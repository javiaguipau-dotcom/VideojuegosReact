# Asistente de IA con Ollama - GuÃ­a de ImplementaciÃ³n

## ğŸ¯ DescripciÃ³n

Sistema de asistente de IA integrado en la aplicaciÃ³n de videojuegos que utiliza Ollama con el modelo `qwen2.5:0.5b` para ayudar a los usuarios a buscar y recomendar juegos de la base de datos.

---

## ğŸ—ï¸ Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚  Puerto 5173
â”‚   React + Vite  â”‚  - BotÃ³n flotante ğŸ¤–
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  - Panel de chat
         â”‚           - Game cards
         â”‚ HTTP
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Backend       â”‚  Puerto 5001
â”‚   Express       â”‚  - /api/ai/chat
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  - Sistema prompts
      â”‚    â”‚
      â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â–¼                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MongoDB  â”‚    â”‚    Ollama      â”‚  Puerto 11434
â”‚ (Juegos) â”‚    â”‚ qwen2.5:0.5b   â”‚  - LLM local
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ Archivos Creados

### Backend (5 archivos)

1. **`backend/src/services/ollamaService.js`**
   - `sendPromptToOllama()` - Comunica con Ollama API
   - `buildSystemPrompt()` - Crea prompt con juegos de BD
   - `extractGameReferences()` - Extrae juegos mencionados

2. **`backend/src/controllers/aiController.js`**
   - `chatWithAI()` - Endpoint principal de chat

3. **`backend/src/routes/aiRoutes.js`**
   - `POST /api/ai/chat` - Ruta protegida

4. **`backend/.env`**
   ```
   OLLAMA_URL=http://localhost:11434
   OLLAMA_MODEL=qwen2.5:0.5b
   ```

5. **`backend/src/server.js`** (modificado)
   - Registra rutas AI

### Frontend (3 archivos)

1. **`src/components/AIAssistant.jsx`**
   - Componente completo del chat
   - 400+ lÃ­neas con toda la funcionalidad

2. **`src/services/aiService.js`**
   - Cliente API para chat

3. **`src/App.jsx`** (modificado)
   - Integra `<AIAssistant />` globalmente

### Docker (3 archivos)

1. **`Dockerfile`**
   - Frontend dockerizado

2. **`.dockerignore`**
   - OptimizaciÃ³n de build

3. **`docker-compose.yml`** (modificado)
   - Servicio frontend
   - Servicio Ollama
   - VolÃºmenes persistentes

---

## ğŸš€ Inicio RÃ¡pido

### 1. Prerequisitos

- Docker Desktop instalado y corriendo
- Node.js 18+ (para desarrollo local)

### 2. Iniciar Ollama y Descargar Modelo

```bash
# Iniciar solo Ollama
docker compose up -d ollama

# Acceder al contenedor
docker exec -it ollama bash

# Descargar modelo (dentro del contenedor)
ollama pull qwen2.5:0.5b

# Probar modelo
ollama run qwen2.5:0.5b
>>> Hola, recomiÃ©ndame un juego de RPG
>>> /bye

# Salir del contenedor
exit
```

### 3. Iniciar Todos los Servicios

```bash
# OpciÃ³n 1: Todos los servicios en Docker
docker compose up

# OpciÃ³n 2: Solo Ollama en Docker, resto local
docker compose up -d ollama mongo
cd backend && npm run dev
cd .. && npm run dev
```

### 4. Probar el Asistente

1. Navega a http://localhost:5173
2. Inicia sesiÃ³n con tu usuario
3. Haz clic en el botÃ³n ğŸ¤– (esquina inferior derecha)
4. Prueba con:
   - "RecomiÃ©ndame un RPG"
   - "Â¿QuÃ© juegos tienes bajo $30?"
   - "MuÃ©strame juegos de estrategia"

---

## ğŸ’¡ CaracterÃ­sticas

### ğŸ¤– Asistente Inteligente

- **Conocimiento especÃ­fico**: Solo responde sobre juegos en la BD
- **Contexto**: Mantiene Ãºltimas 4 conversaciones
- **Limitado**: Rechaza educadamente preguntas fuera de scope

### ğŸ¨ UI/UX

- **BotÃ³n flotante**: Siempre visible, esquina inferior derecha
- **Chat modal**: 400x600px, tema oscuro
- **Chips rÃ¡pidos**: 3 acciones predefinidas
- **Game cards**: Clickeables, navegan a detalle
- **Animaciones**: Loading dots con pulse effect
- **Auto-scroll**: Siempre al Ãºltimo mensaje

### ğŸ”’ Seguridad

- **Endpoint protegido**: Requiere autenticaciÃ³n JWT
- **ValidaciÃ³n**: Input sanitizado
- **Timeouts**: 30s mÃ¡ximo por request
- **Error handling**: Mensajes user-friendly

---

## ğŸ® Ejemplos de Uso

### BÃºsqueda por CategorÃ­a
```
Usuario: "RecomiÃ©ndame un juego de RPG"
AI: "Te recomiendo 'Elden Ring' ($59.99, PS5/PC). Es un RPG 
     con combate desafiante en un mundo de fantasÃ­a oscura."
[Muestra: Card de Elden Ring]
```

### Filtro por Precio
```
Usuario: "Juegos baratos"
AI: "Tenemos: 'Hollow Knight' ($14.99), 'Stardew Valley' 
     ($14.99), y 'Celeste' ($19.99)."
[Muestra: 3 cards de juegos]
```

### Fuera de Scope
```
Usuario: "Â¿QuÃ© tiempo harÃ¡ maÃ±ana?"
AI: "Solo puedo ayudarte con los juegos disponibles en 
     nuestro catÃ¡logo actual."
```

---

## ğŸ› ï¸ ConfiguraciÃ³n

### Variables de Entorno

**Backend (.env)**:
```bash
PORT=5001
MONGODB_URI=mongodb://localhost:27017/videojuegosdb
JWT_SECRET=supersecretkey_change_this_in_production
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=qwen2.5:0.5b
```

**Frontend**:
```bash
VITE_API_URL=http://localhost:5001
```

### Cambiar Modelo

Si quieres usar otro modelo de Ollama:

1. Edita `backend/.env`:
   ```
   OLLAMA_MODEL=llama2:7b
   ```

2. Edita `docker-compose.yml`:
   ```yaml
   OLLAMA_MODEL=llama2:7b
   ```

3. Descarga el modelo:
   ```bash
   docker exec -it ollama ollama pull llama2:7b
   ```

4. Reinicia backend:
   ```bash
   docker compose restart backend
   ```

---

## ğŸ› SoluciÃ³n de Problemas

### Error: "Ollama service is not running"

**Causa**: Contenedor Ollama no estÃ¡ corriendo

**SoluciÃ³n**:
```bash
docker ps  # Verificar contenedores
docker compose up -d ollama  # Iniciar Ollama
docker compose logs ollama   # Ver logs
```

### Error: "Cannot find module 'axios'"

**Causa**: Dependencia no instalada

**SoluciÃ³n**:
```bash
cd backend
npm install
```

### El chat no aparece

**Causa**: No estÃ¡s autenticado

**SoluciÃ³n**: Inicia sesiÃ³n primero (el endpoint es protegido)

### Respuestas lentas

**Causa**: Modelo demasiado grande o CPU lento

**SoluciÃ³n**: Usa un modelo mÃ¡s pequeÃ±o como `qwen2.5:0.5b`

---

## ğŸ“Š Sistema Prompt

El asistente usa un prompt dinÃ¡mico que incluye:

```
You are a helpful video game assistant...

AVAILABLE GAMES:
- "Elden Ring": Action RPG... Price: $59.99. 
  Categories: Rol, Lucha. Platforms: PS5, PC.
- "Cyberpunk 2077": Futuristic RPG... Price: $59.99.
  ...

RULES:
1. ONLY recommend games from the list above
2. Be concise, friendly, helpful
3. If asked about unavailable games, politely decline
4. Mention: title, price, platforms when recommending
5. Answer in user's language (Spanish/English)
6. Keep responses short (2-3 sentences max)
```

---

## ğŸ”„ Flujo de Datos

```
1. Usuario escribe mensaje en AIAssistant.jsx
   â†“
2. Frontend llama aiService.sendMessage()
   â†“
3. Backend (aiController.chatWithAI):
   - Valida input
   - Obtiene todos los juegos de MongoDB
   - Construye system prompt con juegos
   - EnvÃ­a a Ollama con historial
   â†“
4. Ollama procesa y responde
   â†“
5. Backend extrae juegos mencionados
   â†“
6. Frontend recibe { reply, games }
   â†“
7. Muestra mensaje + game cards
```

---

## ğŸ“ API Endpoint

### POST /api/ai/chat

**Headers**:
```
Authorization: Bearer <JWT_TOKEN>
Content-Type: application/json
```

**Request**:
```json
{
  "message": "RecomiÃ©ndame un juego de RPG",
  "conversationHistory": [
    { "role": "user", "content": "Hola" },
    { "role": "assistant", "content": "Â¡Hola! Â¿CÃ³mo puedo ayudarte?" }
  ]
}
```

**Response**:
```json
{
  "reply": "Te recomiendo 'Elden Ring' ($59.99, PS5/PC)...",
  "games": [
    {
      "_id": "...",
      "title": "Elden Ring",
      "precio": 59.99,
      "urlimagen": "...",
      "categorias": ["Rol", "Lucha"],
      "plataformas": ["PS5", "PC"]
    }
  ]
}
```

---

## ğŸ¯ Pruebas con curl

```bash
# Obtener token (login primero)
TOKEN="tu_jwt_token_aqui"

# Enviar mensaje
curl -X POST http://localhost:5001/api/ai/chat \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $TOKEN" \
  -d '{
    "message": "RecomiÃ©ndame un RPG",
    "conversationHistory": []
  }'
```

---

## ğŸ“Œ Notas Importantes

1. **Modelo recomendado**: `qwen2.5:0.5b` (rÃ¡pido, pequeÃ±o)
2. **Requisito**: Docker Desktop debe estar corriendo
3. **AutenticaciÃ³n**: Solo usuarios logueados pueden usar chat
4. **Scope limitado**: AI solo conoce juegos en BD
5. **Historial**: Se mantiene en cliente (no se guarda en BD)
6. **Game cards**: MÃ¡ximo 3 por respuesta
7. **Timeout**: 30 segundos mÃ¡ximo por request

---

## ğŸ”— DocumentaciÃ³n Adicional

- [TESTING_INSTRUCTIONS.md](./TESTING_INSTRUCTIONS.md) - GuÃ­a paso a paso
- [walkthrough.md](./walkthrough.md) - DocumentaciÃ³n tÃ©cnica completa
- [implementation_plan.md](./implementation_plan.md) - Plan original

---

## ğŸ‰ Â¡Listo!

El asistente de IA estÃ¡ completamente implementado y listo para usar. Solo necesitas:

1. âœ… Iniciar Docker Desktop
2. âœ… Descargar el modelo qwen2.5:0.5b
3. âœ… Iniciar los servicios
4. âœ… Â¡Disfrutar del asistente!

**Â¿Dudas?** Consulta `TESTING_INSTRUCTIONS.md`
